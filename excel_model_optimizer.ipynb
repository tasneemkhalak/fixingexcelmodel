{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Excel Model Optimizer - Phase 2: Review and Cleanup\n",
    "Comprehensive cleanup and optimization tool for Excel financial models\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b88c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwings as xw\n",
    "import openpyxl\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Optional, Tuple, Set\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f522bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class OptimizationIssue:\n",
    "    \"\"\"Container for optimization issues found\"\"\"\n",
    "    category: str\n",
    "    severity: str  # 'HIGH', 'MEDIUM', 'LOW'\n",
    "    location: str\n",
    "    description: str\n",
    "    recommendation: str\n",
    "    impact: str\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        return {\n",
    "            'category': self.category,\n",
    "            'severity': self.severity,\n",
    "            'location': self.location,\n",
    "            'description': self.description,\n",
    "            'recommendation': self.recommendation,\n",
    "            'impact': self.impact\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e2dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcelModelOptimizer:\n",
    "    \"\"\"\n",
    "    Comprehensive Excel Model Cleanup and Optimization Tool\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, excel_file_path: str, profiling_results: Optional[Dict] = None):\n",
    "        self.excel_file_path = Path(excel_file_path)\n",
    "        self.profiling_results = profiling_results\n",
    "        self.app = None\n",
    "        self.wb = None\n",
    "        self.wb_openpyxl = None\n",
    "        \n",
    "        # Optimization tracking\n",
    "        self.issues_found = []\n",
    "        self.optimizations_applied = []\n",
    "        self.cleanup_stats = defaultdict(int)\n",
    "        \n",
    "        print(f\"🔧 Excel Model Optimizer initialized for: {self.excel_file_path.name}\")\n",
    "    \n",
    "    def __enter__(self):\n",
    "        \"\"\"Context manager entry\"\"\"\n",
    "        self._open_workbooks()\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Context manager exit\"\"\"\n",
    "        self._close_workbooks()\n",
    "    \n",
    "    def _open_workbooks(self):\n",
    "        \"\"\"Open both xlwings and openpyxl workbooks\"\"\"\n",
    "        try:\n",
    "            # xlwings for operations and VBA\n",
    "            self.app = xw.App(visible=False)\n",
    "            self.wb = self.app.books.open(self.excel_file_path)\n",
    "            \n",
    "            # openpyxl for detailed formula analysis\n",
    "            self.wb_openpyxl = openpyxl.load_workbook(self.excel_file_path)\n",
    "            \n",
    "            print(f\"✅ Workbooks opened for analysis and optimization\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to open Excel file: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _close_workbooks(self):\n",
    "        \"\"\"Close both workbooks\"\"\"\n",
    "        if self.wb_openpyxl:\n",
    "            self.wb_openpyxl.close()\n",
    "        if self.wb:\n",
    "            self.wb.close()\n",
    "        if self.app:\n",
    "            self.app.quit()\n",
    "    \n",
    "    def audit_macros(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Step 1: Macro audit and cleanup\n",
    "        \"\"\"\n",
    "        print(\"\\n🔍 Step 1: Macro Audit and Cleanup...\")\n",
    "        \n",
    "        macro_audit = {\n",
    "            'vba_modules': {},\n",
    "            'procedures': {},\n",
    "            'unused_procedures': [],\n",
    "            'error_handling_coverage': {},\n",
    "            'optimization_suggestions': []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Access VBA project\n",
    "            vb_project = self.wb.api.VBProject\n",
    "            \n",
    "            for component in vb_project.VBComponents:\n",
    "                module_name = component.Name\n",
    "                code_module = component.CodeModule\n",
    "                line_count = code_module.CountOfLines\n",
    "                \n",
    "                print(f\"   Analyzing VBA module: {module_name}\")\n",
    "                \n",
    "                # Read all code\n",
    "                if line_count > 0:\n",
    "                    code_text = code_module.Lines(1, line_count)\n",
    "                    \n",
    "                    # Find procedures\n",
    "                    procedures = self._extract_vba_procedures(code_text)\n",
    "                    \n",
    "                    # Analyze error handling\n",
    "                    error_handling = self._analyze_error_handling(code_text)\n",
    "                    \n",
    "                    macro_audit['vba_modules'][module_name] = {\n",
    "                        'line_count': line_count,\n",
    "                        'procedure_count': len(procedures),\n",
    "                        'procedures': procedures,\n",
    "                        'has_error_handling': error_handling['has_error_handling'],\n",
    "                        'error_coverage_percentage': error_handling['coverage_percentage']\n",
    "                    }\n",
    "                    \n",
    "                    # Check for unused procedures\n",
    "                    for proc_name in procedures:\n",
    "                        if not self._is_procedure_used(proc_name, code_text):\n",
    "                            macro_audit['unused_procedures'].append({\n",
    "                                'module': module_name,\n",
    "                                'procedure': proc_name,\n",
    "                                'recommendation': 'Consider removing if truly unused'\n",
    "                            })\n",
    "                            \n",
    "                            self.issues_found.append(OptimizationIssue(\n",
    "                                category=\"Macro Cleanup\",\n",
    "                                severity=\"LOW\",\n",
    "                                location=f\"{module_name}.{proc_name}\",\n",
    "                                description=\"Potentially unused VBA procedure\",\n",
    "                                recommendation=\"Review and remove if not needed\",\n",
    "                                impact=\"Small file size reduction\"\n",
    "                            ))\n",
    "            \n",
    "            # Generate optimization suggestions\n",
    "            if len(macro_audit['unused_procedures']) > 0:\n",
    "                macro_audit['optimization_suggestions'].append(\n",
    "                    f\"Found {len(macro_audit['unused_procedures'])} potentially unused procedures\"\n",
    "                )\n",
    "            \n",
    "            print(f\"   ✅ Macro audit complete: {len(macro_audit['vba_modules'])} modules analyzed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  VBA analysis limited: {e}\")\n",
    "            macro_audit['error'] = str(e)\n",
    "        \n",
    "        return macro_audit\n",
    "    \n",
    "    def _extract_vba_procedures(self, code_text: str) -> List[str]:\n",
    "        \"\"\"Extract procedure names from VBA code\"\"\"\n",
    "        procedures = []\n",
    "        \n",
    "        # Regex patterns for Sub and Function declarations\n",
    "        patterns = [\n",
    "            r'^\\s*(Public|Private)?\\s*Sub\\s+(\\w+)',\n",
    "            r'^\\s*(Public|Private)?\\s*Function\\s+(\\w+)'\n",
    "        ]\n",
    "        \n",
    "        for line in code_text.split('\\n'):\n",
    "            for pattern in patterns:\n",
    "                match = re.search(pattern, line, re.IGNORECASE)\n",
    "                if match:\n",
    "                    procedure_name = match.group(2)\n",
    "                    if procedure_name not in procedures:\n",
    "                        procedures.append(procedure_name)\n",
    "        \n",
    "        return procedures\n",
    "    \n",
    "    def _analyze_error_handling(self, code_text: str) -> Dict:\n",
    "        \"\"\"Analyze error handling coverage in VBA code\"\"\"\n",
    "        lines = code_text.split('\\n')\n",
    "        total_procedures = len(re.findall(r'^\\s*(Sub|Function)\\s+\\w+', code_text, re.IGNORECASE | re.MULTILINE))\n",
    "        \n",
    "        error_handling_indicators = [\n",
    "            'On Error Resume Next',\n",
    "            'On Error GoTo',\n",
    "            'Err.Number',\n",
    "            'Error Handling',\n",
    "            'Try',\n",
    "            'Catch'\n",
    "        ]\n",
    "        \n",
    "        procedures_with_error_handling = 0\n",
    "        has_error_handling = any(indicator in code_text for indicator in error_handling_indicators)\n",
    "        \n",
    "        if has_error_handling and total_procedures > 0:\n",
    "            # Rough estimate of coverage\n",
    "            procedures_with_error_handling = min(total_procedures, \n",
    "                                               sum(1 for indicator in error_handling_indicators \n",
    "                                                   if indicator in code_text))\n",
    "        \n",
    "        coverage_percentage = (procedures_with_error_handling / max(total_procedures, 1)) * 100\n",
    "        \n",
    "        return {\n",
    "            'has_error_handling': has_error_handling,\n",
    "            'coverage_percentage': round(coverage_percentage, 1),\n",
    "            'total_procedures': total_procedures\n",
    "        }\n",
    "    \n",
    "    def _is_procedure_used(self, procedure_name: str, code_text: str) -> bool:\n",
    "        \"\"\"Check if a procedure is called anywhere in the code\"\"\"\n",
    "        # Simple check - look for procedure name calls\n",
    "        call_patterns = [\n",
    "            rf'\\b{procedure_name}\\s*\\(',  # Function call with parentheses\n",
    "            rf'\\bCall\\s+{procedure_name}\\b',  # Explicit Call statement\n",
    "            rf'^\\s*{procedure_name}\\s*$'  # Simple procedure call\n",
    "        ]\n",
    "        \n",
    "        for pattern in call_patterns:\n",
    "            if re.search(pattern, code_text, re.IGNORECASE | re.MULTILINE):\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def analyze_named_ranges(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Step 2: Named range analysis and cleanup\n",
    "        \"\"\"\n",
    "        print(\"\\n📏 Step 2: Named Range Analysis...\")\n",
    "        \n",
    "        named_range_analysis = {\n",
    "            'total_named_ranges': 0,\n",
    "            'redundant_ranges': [],\n",
    "            'complex_ranges': [],\n",
    "            'unused_ranges': [],\n",
    "            'scope_issues': [],\n",
    "            'optimization_potential': 0\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Get all named ranges\n",
    "            named_ranges = {}\n",
    "            \n",
    "            for name in self.wb.names:\n",
    "                try:\n",
    "                    range_name = name.name\n",
    "                    refers_to = name.refers_to\n",
    "                    scope = \"Workbook\"  # xlwings doesn't easily distinguish scope\n",
    "                    \n",
    "                    named_ranges[range_name] = {\n",
    "                        'refers_to': refers_to,\n",
    "                        'scope': scope,\n",
    "                        'is_complex': self._is_complex_named_range(refers_to)\n",
    "                    }\n",
    "                    \n",
    "                    # Check if range is overly complex\n",
    "                    if named_ranges[range_name]['is_complex']:\n",
    "                        named_range_analysis['complex_ranges'].append({\n",
    "                            'name': range_name,\n",
    "                            'formula': refers_to,\n",
    "                            'recommendation': 'Consider simplifying or replacing with direct references'\n",
    "                        })\n",
    "                        \n",
    "                        self.issues_found.append(OptimizationIssue(\n",
    "                            category=\"Named Range\",\n",
    "                            severity=\"MEDIUM\",\n",
    "                            location=range_name,\n",
    "                            description=\"Complex named range formula\",\n",
    "                            recommendation=\"Simplify formula or use direct cell references\",\n",
    "                            impact=\"Improved calculation speed\"\n",
    "                        ))\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            named_range_analysis['total_named_ranges'] = len(named_ranges)\n",
    "            \n",
    "            # Check for unused named ranges\n",
    "            unused_ranges = self._find_unused_named_ranges(named_ranges)\n",
    "            named_range_analysis['unused_ranges'] = unused_ranges\n",
    "            \n",
    "            # Check for redundant ranges (pointing to same location)\n",
    "            redundant_groups = self._find_redundant_named_ranges(named_ranges)\n",
    "            named_range_analysis['redundant_ranges'] = redundant_groups\n",
    "            \n",
    "            optimization_potential = len(unused_ranges) + sum(len(group) - 1 for group in redundant_groups)\n",
    "            named_range_analysis['optimization_potential'] = optimization_potential\n",
    "            \n",
    "            print(f\"   ✅ Named range analysis: {len(named_ranges)} ranges, {optimization_potential} optimization opportunities\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Named range analysis failed: {e}\")\n",
    "            named_range_analysis['error'] = str(e)\n",
    "        \n",
    "        return named_range_analysis\n",
    "    \n",
    "    def _is_complex_named_range(self, formula: str) -> bool:\n",
    "        \"\"\"Determine if a named range formula is overly complex\"\"\"\n",
    "        if not formula:\n",
    "            return False\n",
    "        \n",
    "        complexity_indicators = [\n",
    "            'INDIRECT(',\n",
    "            'OFFSET(',\n",
    "            'INDEX(',\n",
    "            'MATCH(',\n",
    "            len(formula) > 100,  # Long formulas\n",
    "            formula.count(',') > 5,  # Many parameters\n",
    "            formula.count('(') > 3,  # Nested functions\n",
    "        ]\n",
    "        \n",
    "        return sum(1 for indicator in complexity_indicators if indicator) >= 2\n",
    "    \n",
    "    def _find_unused_named_ranges(self, named_ranges: Dict) -> List[Dict]:\n",
    "        \"\"\"Find named ranges that aren't used anywhere\"\"\"\n",
    "        unused_ranges = []\n",
    "        \n",
    "        # Get all formulas from all sheets\n",
    "        all_formulas = []\n",
    "        for sheet in self.wb_openpyxl.worksheets:\n",
    "            for row in sheet.iter_rows():\n",
    "                for cell in row:\n",
    "                    if cell.data_type == 'f' and cell.value:\n",
    "                        all_formulas.append(str(cell.value))\n",
    "        \n",
    "        all_formula_text = ' '.join(all_formulas).upper()\n",
    "        \n",
    "        for range_name in named_ranges.keys():\n",
    "            if range_name.upper() not in all_formula_text:\n",
    "                unused_ranges.append({\n",
    "                    'name': range_name,\n",
    "                    'refers_to': named_ranges[range_name]['refers_to'],\n",
    "                    'recommendation': 'Consider removing if truly unused'\n",
    "                })\n",
    "                \n",
    "                self.issues_found.append(OptimizationIssue(\n",
    "                    category=\"Named Range\",\n",
    "                    severity=\"LOW\",\n",
    "                    location=range_name,\n",
    "                    description=\"Unused named range\",\n",
    "                    recommendation=\"Remove to reduce file size\",\n",
    "                    impact=\"Cleaner workbook structure\"\n",
    "                ))\n",
    "        \n",
    "        return unused_ranges\n",
    "    \n",
    "    def _find_redundant_named_ranges(self, named_ranges: Dict) -> List[List[str]]:\n",
    "        \"\"\"Find named ranges that refer to the same location\"\"\"\n",
    "        refers_to_groups = defaultdict(list)\n",
    "        \n",
    "        for range_name, info in named_ranges.items():\n",
    "            refers_to_groups[info['refers_to']].append(range_name)\n",
    "        \n",
    "        # Return groups with more than one named range\n",
    "        redundant_groups = [group for group in refers_to_groups.values() if len(group) > 1]\n",
    "        \n",
    "        for group in redundant_groups:\n",
    "            self.issues_found.append(OptimizationIssue(\n",
    "                category=\"Named Range\",\n",
    "                severity=\"LOW\",\n",
    "                location=', '.join(group),\n",
    "                description=\"Multiple named ranges pointing to same location\",\n",
    "                recommendation=\"Keep one and remove others\",\n",
    "                impact=\"Reduced confusion and file size\"\n",
    "            ))\n",
    "        \n",
    "        return redundant_groups\n",
    "    \n",
    "    def analyze_formulas(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Step 3: Formula analysis and optimization\n",
    "        \"\"\"\n",
    "        print(\"\\n📐 Step 3: Formula Analysis and Optimization...\")\n",
    "        \n",
    "        formula_analysis = {\n",
    "            'total_formulas': 0,\n",
    "            'volatile_functions': {},\n",
    "            'array_formulas': [],\n",
    "            'circular_references': [],\n",
    "            'complex_formulas': [],\n",
    "            'redundant_calculations': [],\n",
    "            'optimization_opportunities': 0\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            total_formulas = 0\n",
    "            volatile_count = defaultdict(int)\n",
    "            \n",
    "            # Volatile functions to look for\n",
    "            volatile_functions = ['NOW()', 'TODAY()', 'INDIRECT(', 'OFFSET(', 'RAND()', 'RANDBETWEEN(']\n",
    "            \n",
    "            for sheet_name in self.wb_openpyxl.sheetnames:\n",
    "                sheet = self.wb_openpyxl[sheet_name]\n",
    "                sheet_formulas = {}\n",
    "                \n",
    "                print(f\"   Analyzing formulas in: {sheet_name}\")\n",
    "                \n",
    "                for row in sheet.iter_rows():\n",
    "                    for cell in row:\n",
    "                        if cell.data_type == 'f' and cell.value:\n",
    "                            total_formulas += 1\n",
    "                            formula = str(cell.value).upper()\n",
    "                            cell_address = f\"{sheet_name}!{cell.coordinate}\"\n",
    "                            \n",
    "                            # Check for volatile functions\n",
    "                            for volatile_func in volatile_functions:\n",
    "                                if volatile_func in formula:\n",
    "                                    volatile_count[volatile_func] += 1\n",
    "                            \n",
    "                            # Check for array formulas\n",
    "                            if cell.data_type == 'f' and hasattr(cell, 'array_formula') and cell.array_formula:\n",
    "                                formula_analysis['array_formulas'].append({\n",
    "                                    'location': cell_address,\n",
    "                                    'formula': cell.value,\n",
    "                                    'recommendation': 'Consider optimizing if causing performance issues'\n",
    "                                })\n",
    "                            \n",
    "                            # Check for overly complex formulas\n",
    "                            if self._is_complex_formula(formula):\n",
    "                                formula_analysis['complex_formulas'].append({\n",
    "                                    'location': cell_address,\n",
    "                                    'formula': cell.value,\n",
    "                                    'length': len(formula),\n",
    "                                    'nesting_level': formula.count('('),\n",
    "                                    'recommendation': 'Consider breaking into multiple steps'\n",
    "                                })\n",
    "                                \n",
    "                                self.issues_found.append(OptimizationIssue(\n",
    "                                    category=\"Formula Complexity\",\n",
    "                                    severity=\"MEDIUM\",\n",
    "                                    location=cell_address,\n",
    "                                    description=\"Overly complex formula\",\n",
    "                                    recommendation=\"Break into simpler components\",\n",
    "                                    impact=\"Improved readability and maintainability\"\n",
    "                                ))\n",
    "                            \n",
    "                            # Store for redundancy checking\n",
    "                            if formula not in sheet_formulas:\n",
    "                                sheet_formulas[formula] = []\n",
    "                            sheet_formulas[formula].append(cell_address)\n",
    "                \n",
    "                # Find redundant formulas in this sheet\n",
    "                for formula, locations in sheet_formulas.items():\n",
    "                    if len(locations) > 1:\n",
    "                        formula_analysis['redundant_calculations'].append({\n",
    "                            'formula': formula,\n",
    "                            'locations': locations,\n",
    "                            'count': len(locations),\n",
    "                            'recommendation': 'Consider calculating once and referencing'\n",
    "                        })\n",
    "            \n",
    "            formula_analysis['total_formulas'] = total_formulas\n",
    "            formula_analysis['volatile_functions'] = dict(volatile_count)\n",
    "            \n",
    "            # Calculate optimization opportunities\n",
    "            optimization_opportunities = (\n",
    "                sum(volatile_count.values()) +\n",
    "                len(formula_analysis['complex_formulas']) +\n",
    "                len(formula_analysis['redundant_calculations'])\n",
    "            )\n",
    "            formula_analysis['optimization_opportunities'] = optimization_opportunities\n",
    "            \n",
    "            print(f\"   ✅ Formula analysis: {total_formulas} formulas, {optimization_opportunities} optimization opportunities\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Formula analysis failed: {e}\")\n",
    "            formula_analysis['error'] = str(e)\n",
    "        \n",
    "        return formula_analysis\n",
    "    \n",
    "    def _is_complex_formula(self, formula: str) -> bool:\n",
    "        \"\"\"Determine if a formula is overly complex\"\"\"\n",
    "        complexity_score = 0\n",
    "        \n",
    "        # Length-based complexity\n",
    "        if len(formula) > 200:\n",
    "            complexity_score += 2\n",
    "        elif len(formula) > 100:\n",
    "            complexity_score += 1\n",
    "        \n",
    "        # Nesting complexity\n",
    "        nesting_level = formula.count('(')\n",
    "        if nesting_level > 5:\n",
    "            complexity_score += 2\n",
    "        elif nesting_level > 3:\n",
    "            complexity_score += 1\n",
    "        \n",
    "        # Function count\n",
    "        function_count = len(re.findall(r'\\w+\\(', formula))\n",
    "        if function_count > 5:\n",
    "            complexity_score += 1\n",
    "        \n",
    "        # Reference complexity\n",
    "        reference_count = len(re.findall(r'[A-Z]+[0-9]+', formula))\n",
    "        if reference_count > 10:\n",
    "            complexity_score += 1\n",
    "        \n",
    "        return complexity_score >= 3\n",
    "    \n",
    "    def analyze_workbook_structure(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Step 4: Comprehensive workbook structure analysis\n",
    "        \"\"\"\n",
    "        print(\"\\n🏗️  Step 4: Workbook Structure Analysis...\")\n",
    "        \n",
    "        structure_analysis = {\n",
    "            'file_size_analysis': {},\n",
    "            'worksheet_analysis': {},\n",
    "            'conditional_formatting': {},\n",
    "            'data_types': {},\n",
    "            'range_references': {},\n",
    "            'optimization_recommendations': []\n",
    "        }\n",
    "        \n",
    "        # File size analysis\n",
    "        file_size = self.excel_file_path.stat().st_size\n",
    "        structure_analysis['file_size_analysis'] = {\n",
    "            'total_size_bytes': file_size,\n",
    "            'total_size_mb': round(file_size / (1024 * 1024), 2)\n",
    "        }\n",
    "        \n",
    "        # Analyze each worksheet\n",
    "        for sheet in self.wb.sheets:\n",
    "            sheet_name = sheet.name\n",
    "            print(f\"   Analyzing structure of: {sheet_name}\")\n",
    "            \n",
    "            try:\n",
    "                used_range = sheet.used_range\n",
    "                if used_range:\n",
    "                    # Get dimensions\n",
    "                    last_row = used_range.last_cell.row\n",
    "                    last_col = used_range.last_cell.column\n",
    "                    \n",
    "                    # Analyze data types and potential issues\n",
    "                    data_type_analysis = self._analyze_data_types(sheet, used_range)\n",
    "                    range_ref_analysis = self._analyze_range_references(sheet)\n",
    "                    \n",
    "                    structure_analysis['worksheet_analysis'][sheet_name] = {\n",
    "                        'used_range': f\"A1:{used_range.last_cell.address}\",\n",
    "                        'dimensions': f\"{last_row} rows x {last_col} columns\",\n",
    "                        'total_cells': last_row * last_col,\n",
    "                        'data_types': data_type_analysis,\n",
    "                        'range_references': range_ref_analysis\n",
    "                    }\n",
    "                    \n",
    "                    # Check for excessive worksheet size\n",
    "                    if last_row > 10000 or last_col > 100:\n",
    "                        self.issues_found.append(OptimizationIssue(\n",
    "                            category=\"Worksheet Structure\",\n",
    "                            severity=\"MEDIUM\",\n",
    "                            location=sheet_name,\n",
    "                            description=f\"Large worksheet dimensions: {last_row}x{last_col}\",\n",
    "                            recommendation=\"Consider data optimization or splitting\",\n",
    "                            impact=\"Improved performance and memory usage\"\n",
    "                        ))\n",
    "                \n",
    "            except Exception as e:\n",
    "                structure_analysis['worksheet_analysis'][sheet_name] = {\n",
    "                    'error': str(e)\n",
    "                }\n",
    "        \n",
    "        print(f\"   ✅ Structure analysis complete\")\n",
    "        \n",
    "        return structure_analysis\n",
    "    \n",
    "    def _analyze_data_types(self, sheet, used_range) -> Dict:\n",
    "        \"\"\"Analyze data types in a worksheet\"\"\"\n",
    "        data_types = defaultdict(int)\n",
    "        potential_issues = []\n",
    "        \n",
    "        # Sample cells to avoid performance issues\n",
    "        sample_size = min(1000, used_range.count)\n",
    "        \n",
    "        for i in range(sample_size):\n",
    "            try:\n",
    "                row = (i % used_range.last_cell.row) + 1\n",
    "                col = (i // used_range.last_cell.row) + 1\n",
    "                \n",
    "                if row <= used_range.last_cell.row and col <= used_range.last_cell.column:\n",
    "                    cell = sheet.range(row, col)\n",
    "                    \n",
    "                    if cell.value is not None:\n",
    "                        value_type = type(cell.value).__name__\n",
    "                        data_types[value_type] += 1\n",
    "                        \n",
    "                        # Check for text-as-numbers (common issue)\n",
    "                        if isinstance(cell.value, str):\n",
    "                            try:\n",
    "                                float(cell.value)\n",
    "                                potential_issues.append(f\"Text-as-number at {cell.address}\")\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return {\n",
    "            'type_distribution': dict(data_types),\n",
    "            'sample_size': sample_size,\n",
    "            'potential_issues': potential_issues[:10]  # Limit to first 10\n",
    "        }\n",
    "    \n",
    "    def _analyze_range_references(self, sheet) -> Dict:\n",
    "        \"\"\"Analyze range references for optimization opportunities\"\"\"\n",
    "        full_column_refs = 0\n",
    "        full_row_refs = 0\n",
    "        external_refs = 0\n",
    "        \n",
    "        try:\n",
    "            # Sample formulas to check for inefficient references\n",
    "            if hasattr(sheet, 'used_range') and sheet.used_range:\n",
    "                for row in range(1, min(sheet.used_range.last_cell.row + 1, 100)):  # Sample first 100 rows\n",
    "                    for col in range(1, min(sheet.used_range.last_cell.column + 1, 26)):  # Sample first 26 columns\n",
    "                        try:\n",
    "                            cell = sheet.range(row, col)\n",
    "                            if cell.formula:\n",
    "                                formula = str(cell.formula)\n",
    "                                \n",
    "                                # Check for full column references (A:A, B:B, etc.)\n",
    "                                if re.search(r'[A-Z]+:[A-Z]+', formula):\n",
    "                                    full_column_refs += 1\n",
    "                                \n",
    "                                # Check for full row references (1:1, 2:2, etc.)\n",
    "                                if re.search(r'\\d+:\\d+', formula):\n",
    "                                    full_row_refs += 1\n",
    "                                \n",
    "                                # Check for external references\n",
    "                                if '[' in formula or '!' in formula and sheet.name not in formula:\n",
    "                                    external_refs += 1\n",
    "                        except:\n",
    "                            continue\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        issues = []\n",
    "        if full_column_refs > 5:\n",
    "            issues.append(\"Many full column references found - consider using specific ranges\")\n",
    "        if external_refs > 10:\n",
    "            issues.append(\"Many external references - consider data consolidation\")\n",
    "        \n",
    "        return {\n",
    "            'full_column_references': full_column_refs,\n",
    "            'full_row_references': full_row_refs,\n",
    "            'external_references': external_refs,\n",
    "            'optimization_issues': issues\n",
    "        }\n",
    "    \n",
    "    def generate_optimization_report(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate comprehensive optimization report\n",
    "        \"\"\"\n",
    "        print(\"\\n📊 Generating Optimization Report...\")\n",
    "        \n",
    "        # Run all analysis steps\n",
    "        macro_audit = self.audit_macros()\n",
    "        named_range_analysis = self.analyze_named_ranges()\n",
    "        formula_analysis = self.analyze_formulas()\n",
    "        structure_analysis = self.analyze_workbook_structure()\n",
    "        \n",
    "        # Compile comprehensive report\n",
    "        optimization_report = {\n",
    "            'report_generated': datetime.now().isoformat(),\n",
    "            'excel_file': str(self.excel_file_path),\n",
    "            'summary': {\n",
    "                'total_issues_found': len(self.issues_found),\n",
    "                'high_priority_issues': len([i for i in self.issues_found if i.severity == 'HIGH']),\n",
    "                'medium_priority_issues': len([i for i in self.issues_found if i.severity == 'MEDIUM']),\n",
    "                'low_priority_issues': len([i for i in self.issues_found if i.severity == 'LOW'])\n",
    "            },\n",
    "            'detailed_analysis': {\n",
    "                'macro_audit': macro_audit,\n",
    "                'named_range_analysis': named_range_analysis,\n",
    "                'formula_analysis': formula_analysis,\n",
    "                'structure_analysis': structure_analysis\n",
    "            },\n",
    "            'all_issues': [issue.to_dict() for issue in self.issues_found],\n",
    "            'priority_recommendations': self._generate_priority_recommendations(),\n",
    "            'cleanup_stats': dict(self.cleanup_stats)\n",
    "        }\n",
    "        \n",
    "        print(f\"   ✅ Optimization report generated: {len(self.issues_found)} issues identified\")\n",
    "        \n",
    "        return optimization_report\n",
    "    \n",
    "    def _generate_priority_recommendations(self) -> List[Dict]:\n",
    "        \"\"\"Generate prioritized list of optimization recommendations\"\"\"\n",
    "        priority_recs = []\n",
    "        \n",
    "        # Group issues by category and severity\n",
    "        issue_groups = defaultdict(list)\n",
    "        for issue in self.issues_found:\n",
    "            issue_groups[issue.category].append(issue)\n",
    "        \n",
    "        # Generate category-based recommendations\n",
    "        for category, issues in issue_groups.items():\n",
    "            high_priority = [i for i in issues if i.severity == 'HIGH']\n",
    "            medium_priority = [i for i in issues if i.severity == 'MEDIUM']\n",
    "            \n",
    "            if high_priority:\n",
    "                priority_recs.append({\n",
    "                    'priority': 1,\n",
    "                    'category': category,\n",
    "                    'issue_count': len(high_priority),\n",
    "                    'recommendation': f\"Address {len(high_priority)} high-priority {category.lower()} issues\",\n",
    "                    'expected_impact': \"Significant performance improvement\"\n",
    "                })\n",
    "            \n",
    "            if medium_priority:\n",
    "                priority_recs.append({\n",
    "                    'priority': 2,\n",
    "                    'category': category,\n",
    "                    'issue_count': len(medium_priority),\n",
    "                    'recommendation': f\"Review {len(medium_priority)} medium-priority {category.lower()} issues\",\n",
    "                    'expected_impact': \"Moderate performance improvement\"\n",
    "                })\n",
    "        \n",
    "        return sorted(priority_recs, key=lambda x: x['priority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23fa055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function for Excel Model Optimizer\n",
    "    \"\"\"\n",
    "    excel_file = \"project_finance_lease_model.xlsm\"\n",
    "    \n",
    "    if not Path(excel_file).exists():\n",
    "        print(f\"❌ Excel file not found: {excel_file}\")\n",
    "        return\n",
    "    \n",
    "    # Load profiling results if available\n",
    "    profiling_file = Path(excel_file).stem + \"_profiling_results.json\"\n",
    "    profiling_results = None\n",
    "    \n",
    "    if Path(profiling_file).exists():\n",
    "        with open(profiling_file, 'r') as f:\n",
    "            profiling_results = json.load(f)\n",
    "        print(f\"📂 Loaded profiling results from: {profiling_file}\")\n",
    "    \n",
    "    # Run optimization analysis\n",
    "    with ExcelModelOptimizer(excel_file, profiling_results) as optimizer:\n",
    "        report = optimizer.generate_optimization_report()\n",
    "        \n",
    "        # Save optimization report\n",
    "        output_file = Path(excel_file).stem + \"_optimization_report.json\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        \n",
    "        print(f\"💾 Optimization report saved to: {output_file}\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"📋 OPTIMIZATION SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Issues Found: {report['summary']['total_issues_found']}\")\n",
    "        print(f\"  - High Priority: {report['summary']['high_priority_issues']}\")\n",
    "        print(f\"  - Medium Priority: {report['summary']['medium_priority_issues']}\")\n",
    "        print(f\"  - Low Priority: {report['summary']['low_priority_issues']}\")\n",
    "        \n",
    "        if report['priority_recommendations']:\n",
    "            print(f\"\\n🎯 TOP RECOMMENDATIONS:\")\n",
    "            for rec in report['priority_recommendations'][:5]:\n",
    "                print(f\"  {rec['priority']}. {rec['recommendation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
